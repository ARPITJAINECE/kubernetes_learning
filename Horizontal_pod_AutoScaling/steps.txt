1️⃣ Identify the workload : 
Choose which app needs auto-scaling (frontend, backend, workers).
It must be stateless and able to run multiple replicas.

2️⃣ Define resource requests : 
Set CPU and memory requests in the Deployment.
HPA uses these values as the baseline for scaling.

3️⃣ Install Metrics Server : 
Deploy Metrics Server so Kubernetes can read Pod CPU & memory.
Without it, HPA cannot make decisions.

4️⃣ Choose scaling metrics : 
Decide whether to scale using CPU, memory, or both.
Also choose the target utilization (for example 50% CPU).

5️⃣ Create the HPA : 
Define minReplicas, maxReplicas, and target metrics in the HPA YAML.
Link it to the Deployment you want to scale.

6️⃣ Apply the HPA : 
Use kubectl apply -f hpa.yaml to enable autoscaling.
HPA immediately starts monitoring the pods.

7️⃣ Monitor behavior : 
Check scaling using kubectl get hpa and kubectl describe hpa.
Verify that replicas change when load changes.

8️⃣ Tune for production : 
Adjust requests, min/max replicas, and targets for best performance.
This prevents over-scaling or under-scaling.